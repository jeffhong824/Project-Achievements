{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Data Selected 2012_003_1.edf\n",
      "D:/Record/Other/履歷/myself/4碩士論文finish/畢業論文/程式/step6_new_data/data/2012_003_1.edf\n",
      "Extracting EDF parameters from D:\\Record\\Other\\履歷\\myself\\4碩士論文finish\\畢業論文\\程式\\step6_new_data\\data\\2012_003_1.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 302079  =      0.000 ...  1179.996 secs...\n",
      "New Model Selected lr-0629-ver1.pickle\n",
      "1536 864\n",
      "2012_003_1.edf\n",
      "lr-0629-ver1.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tingchun.TC.Hung\\Anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator PCA from version 0.22.2 when using version 0.24.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Tingchun.TC.Hung\\Anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator Normalizer from version 0.22.2 when using version 0.24.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Tingchun.TC.Hung\\Anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.22.2 when using version 0.24.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "C:\\Users\\Tingchun.TC.Hung\\Anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\base.py:315: UserWarning: Trying to unpickle estimator Pipeline from version 0.22.2 when using version 0.24.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 0 0 0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import tkinter.font as tkFont\n",
    "\n",
    "import os\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "from os import walk\n",
    "\n",
    "import tkinter as tk  # 使用Tkinter前需要先匯入\n",
    "import tkinter.messagebox\n",
    "import pickle\n",
    "from PIL import Image,ImageTk\n",
    "from tkinter.filedialog import askdirectory\n",
    "\n",
    "#task 1\n",
    "from xlrd import open_workbook \n",
    "import os\n",
    "from os import listdir , mkdir\n",
    "from os.path import isfile, isdir, join,splitext\n",
    "from os import walk\n",
    "from os.path import isdir\n",
    "from shutil import copyfile\n",
    "\n",
    "\n",
    "# task2中 資料擷取 resample  並記錄id  \n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import mne\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "from mne.decoding import CSP\n",
    "\n",
    "\n",
    "import math\n",
    "import scipy.io as sio \n",
    "from scipy.stats import entropy,skew,kurtosis\n",
    "import pandas as pd\n",
    "from math import e\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(1)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "from matplotlib.backends.backend_tkagg import (\n",
    "    FigureCanvasTkAgg, NavigationToolbar2Tk)\n",
    "# Implement the default Matplotlib key bindings.\n",
    "from matplotlib.backend_bases import key_press_handler\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "def tidy_up(channel_position,all_data):\n",
    "\n",
    "    Cannel=['EEG Fp1-Ref','EEG Fp2-Ref','EEG F7-Ref','EEG F3-Ref','EEG Fz-Ref','EEG F4-Ref','EEG F8-Ref','EEG T3-Ref','EEG C3-Ref','EEG Cz-Ref','EEG C4-Ref','EEG T4-Ref',\n",
    "            'EEG T5-Ref','EEG P3-Ref','EEG Pz-Ref','EEG P4-Ref','EEG T6-Ref','EEG O1-Ref','EEG O2-Ref','EEG A1-Ref','EEG A2-Ref','Photic Ph'\n",
    "           ]\n",
    "    count_already_find_channel = 0\n",
    "    sort_channel_list = []\n",
    "    for find_channel in Cannel:\n",
    "        #each channel - data\n",
    "        for channel_position_each_channel in range(len(channel_position)):\n",
    "            #find channel position\n",
    "            if (channel_position[channel_position_each_channel].lower() == find_channel.lower()):\n",
    "                count_already_find_channel+=1\n",
    "                sort_channel_list.append(channel_position_each_channel)\n",
    "    if(count_already_find_channel==22):      \n",
    "        #save want channel data\n",
    "        all_data_save = all_data[sort_channel_list]\n",
    "        return all_data_save,sort_channel_list,1\n",
    "    else:\n",
    "        Cannel[21]='Photic-REF'\n",
    "        count_already_find_channel = 0\n",
    "        sort_channel_list = []\n",
    "        for find_channel in Cannel:\n",
    "            #each channel - data\n",
    "            for channel_position_each_channel in range(len(channel_position)):\n",
    "                #find channel position\n",
    "                if (channel_position[channel_position_each_channel].lower() == find_channel.lower()):\n",
    "                    count_already_find_channel+=1\n",
    "                    sort_channel_list.append(channel_position_each_channel)\n",
    "        if(count_already_find_channel==22):      \n",
    "            #save want channel data\n",
    "            all_data_save = all_data[sort_channel_list]\n",
    "            return all_data_save,sort_channel_list,1        \n",
    "        else:\n",
    "            sort_channel_list=[]\n",
    "            all_data_save =[]\n",
    "            return all_data_save,sort_channel_list,0\n",
    "\n",
    "def save_data(data,want_append_data):\n",
    "    collect_data_num=data.shape[0]\n",
    "    collect_data=np.zeros((collect_data_num+1,22,2000))\n",
    "    collect_data[0:collect_data_num]=data\n",
    "    collect_data[collect_data_num]=want_append_data\n",
    "    return collect_data\n",
    "\n",
    "def photo_stimulate_position(photo_times_list,photo_size_diff_list,data_math,collect_data,collect_data_after,collect_data_befor,data_name,sampling_rate,want_sampling_rate,select_data_save):\n",
    "#def photo_stimulate_position(collect_data,collect_data_after,collect_data_befor,list_name[data_num][:5],raw.info['sfreq'],want_sampling_rate,select_data_save):\n",
    "    photo_channel = select_data_save[21,:]\n",
    "    photo_point = np.where(photo_channel!=0)[0]\n",
    "    photo_point2 = np.where(photo_channel>200)[0]\n",
    "    if(len(photo_point2)==0):\n",
    "        photo_size_diff_list.append(data_name)\n",
    "    except_calibrate_photo_point = np.where(photo_point>10000)[0]\n",
    "    real_photo_point = photo_point[except_calibrate_photo_point]\n",
    "    find_real_photo_point_diff=np.diff(real_photo_point)\n",
    "    photo_frequency_change_position=np.where(find_real_photo_point_diff>2000)[0]\n",
    "    howmanyphoto=len(photo_frequency_change_position)\n",
    "    photo_times_list.append(howmanyphoto)\n",
    "    success_time = 0\n",
    "    if(howmanyphoto!=0):\n",
    "        for photo_times in range(howmanyphoto):\n",
    "            if (photo_times !=0):\n",
    "                switch=1\n",
    "            else:\n",
    "                switch=0\n",
    "            #the same hz point to photo change position\n",
    "            event_data = select_data_save[:,real_photo_point[0+switch*(1+photo_frequency_change_position[photo_times-1])]:1+real_photo_point[photo_frequency_change_position[photo_times]]]\n",
    "            event_data_long = len(event_data[0,:])\n",
    "            sampling_long=int(event_data_long*(want_sampling_rate/sampling_rate))\n",
    "            event_data_after = select_data_save[:,real_photo_point[0+switch*(1+photo_frequency_change_position[photo_times-1])]+event_data_long:1+real_photo_point[photo_frequency_change_position[photo_times]]+event_data_long]\n",
    "            event_data_befor = select_data_save[:,real_photo_point[0+switch*(1+photo_frequency_change_position[photo_times-1])]-event_data_long:1+real_photo_point[photo_frequency_change_position[photo_times]]-event_data_long]\n",
    "            #resample\n",
    "            if(sampling_rate!=250):\n",
    "                resampling_data=signal.resample(event_data,sampling_long,axis=1)\n",
    "                resampling_data_after=signal.resample(event_data_after,sampling_long,axis=1)\n",
    "                resampling_data_befor=signal.resample(event_data_befor,sampling_long,axis=1)\n",
    "            else:\n",
    "                resampling_data=event_data\n",
    "                resampling_data_after=event_data_after\n",
    "                resampling_data_befor=event_data_befor\n",
    "            #cut down\n",
    "            if(len(resampling_data[0,:])>2000):\n",
    "                process_event_data = resampling_data[:,0:2000]\n",
    "                process_event_data_after = resampling_data_after[:,0:2000]\n",
    "                process_event_data_befor = resampling_data_befor[:,0:2000]\n",
    "                collect_data=save_data(collect_data,process_event_data)\n",
    "                collect_data_after=save_data(collect_data_after,process_event_data_after)\n",
    "                collect_data_befor=save_data(collect_data_befor,process_event_data_befor)\n",
    "                data_math+=1\n",
    "                success_time+=1\n",
    "            else:\n",
    "                process_event_data = resampling_data\n",
    "                process_event_data_after = resampling_data_after\n",
    "                process_event_data_befor = resampling_data_befor\n",
    "\n",
    "    return success_time,photo_times_list,photo_size_diff_list,data_math,collect_data,collect_data_after,collect_data_befor\n",
    "\n",
    "def MorletWavelet(fc):\n",
    "\n",
    "    F_RATIO = 7\n",
    "    Zalpha2 = 3.3\n",
    "\n",
    "    sigma_f = fc/F_RATIO\n",
    "    sigma_t = 1/(2*math.pi*sigma_f)\n",
    "    A = 1/((sigma_t*(math.pi**0.5))**0.5)\n",
    "    #print(A)\n",
    "    max_t = math.ceil(Zalpha2 * sigma_t)\n",
    "\n",
    "    t = []\n",
    "    for t_index in range(-max_t,max_t+1):\n",
    "        t.append(t_index)\n",
    "    MW = []\n",
    "    for t_multi in range(len(t)):\n",
    "        v1 = 1/(-2*sigma_t**2)\n",
    "        v2 = (2j)*math.pi*fc\n",
    "        want = t[t_multi]*(t[t_multi]*v1+v2)\n",
    "        MW.append(A * e**(want))\n",
    "    return MW\n",
    "\n",
    "def tfa_morlet(td, fs, fmin, fmax, fstep):\n",
    "    TFmap = []\n",
    "\n",
    "    for fc in range(fmin,fmax+1):#,fs\n",
    "        MW = MorletWavelet(fc/fs)  \n",
    "        #np.convolve(td, MW, 'same')\n",
    "\n",
    "        npad = len(MW) - 1\n",
    "        u_padded = np.pad(td, (npad//2, npad - npad//2), mode='constant')\n",
    "        cr = np.convolve(u_padded, MW, 'valid')\n",
    "\n",
    "        TFmap.append(abs(cr))\n",
    "    return TFmap\n",
    "\n",
    "all_path = \"D:/Record/Other/履歷/myself/4碩士論文finish/畢業論文/程式/step6_new_data/\"\n",
    "path_model_intro = all_path+\"model_intro/\"\n",
    "\n",
    "model_name=[]\n",
    "path_model = all_path+\"model/\"    #獲取當前路徑 !!!!!!!!!!!!!!\n",
    "\n",
    "num_dirs = 0 #路徑下資料夾數量\n",
    "num_files = 0 #路徑下檔案數量(包括資料夾)\n",
    "num_files_rec = 0 #路徑下檔案數量,包括子資料夾裡的檔案數量，不包括空資料夾\n",
    "\n",
    "\n",
    "for root,dirs,files in os.walk(path_model):    #遍歷統計''\n",
    "    for name in files:\n",
    "        num_dirs += 1\n",
    "        #print (os.path.join(root,name),\"資料夾名稱:\",name)\n",
    "        model_name.append(name)\n",
    "        \n",
    "        \n",
    "data_name=[]\n",
    "path_data = all_path+\"data/\"    #獲取當前路徑 !!!!!!!!!!!!!!\n",
    "\n",
    "num_dirs = 0 #路徑下資料夾數量\n",
    "num_files = 0 #路徑下檔案數量(包括資料夾)\n",
    "num_files_rec = 0 #路徑下檔案數量,包括子資料夾裡的檔案數量，不包括空資料夾\n",
    "\n",
    "for root,dirs,files in os.walk(path_data):    #遍歷統計''\n",
    "    for name in files:\n",
    "        num_dirs += 1\n",
    "        #print (os.path.join(root,name),\"資料夾名稱:\",name)\n",
    "        data_name.append(name)\n",
    "\n",
    "path_save =  all_path+'step/'\n",
    "if not os.path.isdir(path_save+'create_data/'):\n",
    "    os.mkdir(path_save+'create_data/')\n",
    "if not os.path.isdir(path_save+'bandpass/'):\n",
    "    os.mkdir(path_save+'bandpass/')\n",
    "if not os.path.isdir(path_save+'erd_ers/'):\n",
    "    os.mkdir(path_save+'erd_ers/')\n",
    "if not os.path.isdir(path_save+'wavelet/'):\n",
    "    os.mkdir(path_save+'wavelet/')\n",
    "if not os.path.isdir(path_save+'ans/'):\n",
    "    os.mkdir(path_save+'ans/')\n",
    "path_create = path_save+'create_data/'\n",
    "path_bandpass = path_save+'bandpass/'\n",
    "path_erd_ers = path_save+'erd_ers/'\n",
    "path_wavelet = path_save+'wavelet/'\n",
    "path_ans = path_save+'ans/'\n",
    "\n",
    "channel_name = ['EEG Fp1-Ref','EEG Fp2-Ref','EEG F7-Ref','EEG F3-Ref','EEG Fz-Ref','EEG F4-Ref','EEG F8-Ref','EEG T3-Ref','EEG C3-Ref','EEG Cz-Ref','EEG C4-Ref','EEG T4-Ref',\n",
    "            'EEG T5-Ref','EEG P3-Ref','EEG Pz-Ref','EEG P4-Ref','EEG T6-Ref','EEG O1-Ref','EEG O2-Ref','EEG A1-Ref','EEG A2-Ref'  ]\n",
    "\n",
    "window = tk.Tk() \n",
    "window.geometry('1100x680') #470x300\n",
    "window.iconbitmap(all_path+'icon/eeg_icon.ico')\n",
    "window.resizable(False, False)\n",
    "#window.minsize(470,300)\n",
    "#window.maxsize(940, 600)\n",
    "window.title(' Taipei Veterans General Hospital')\n",
    "window.configure(bg='white')#bg='white' \n",
    "\n",
    "add_pic = 5\n",
    "add_num = 100\n",
    "\n",
    "canvas_back_left = tk.Canvas(window, width=363, height=230, bg=\"white\")\n",
    "canvas_back_left.place(x=5, y=10)\n",
    "canvas_back_right_1 = tk.Canvas(window, width=670, height=105, bg=\"white\")\n",
    "canvas_back_right_1.place(x=400, y=10)\n",
    "canvas_back_right_2 = tk.Canvas(window, width=670, height=105, bg=\"white\")\n",
    "canvas_back_right_2.place(x=400, y=135)\n",
    "\n",
    "photo_eeg = tk.PhotoImage(file=all_path+\"icon/eeg.png\")\n",
    "photo_eeg = photo_eeg.zoom(4)\n",
    "photo_eeg = photo_eeg.subsample(8)\n",
    "imgLabel_eeg = tk.Label(window,image=photo_eeg,bg='white')#把圖片整合到標簽類中\n",
    "imgLabel_eeg.place(x=30, y=7+add_pic)\n",
    "\n",
    "photo_ai = tk.PhotoImage(file=all_path+\"icon/ai.png\")\n",
    "photo_ai = photo_ai.zoom(2)\n",
    "photo_ai = photo_ai.subsample(10)\n",
    "imgLabel_ai = tk.Label(window,image=photo_ai,bg='white')#把圖片整合到標簽類中\n",
    "imgLabel_ai.place(x=7, y=110+add_pic)\n",
    "\n",
    "photo_eeg_run_1 = tk.PhotoImage(file=all_path+\"icon/eeg_run.png\")\n",
    "photo_eeg_run_1 = photo_eeg_run_1.zoom(4)\n",
    "photo_eeg_run_1 = photo_eeg_run_1.subsample(8)\n",
    "photo_eeg_run_2 = tk.PhotoImage(file=all_path+\"icon/eeg_run.png\")\n",
    "photo_eeg_run_2 = photo_eeg_run_2.zoom(4)\n",
    "photo_eeg_run_2 = photo_eeg_run_2.subsample(8)\n",
    "\n",
    "#photo_eeg_run_space_1 = tk.PhotoImage(file=all_path+\"icon/eeg_run_space.png\")\n",
    "#photo_eeg_run_space_1 = photo_eeg_run_space_1.zoom(4)\n",
    "#photo_eeg_run_space_1 = photo_eeg_run_space_1.subsample(8)\n",
    "#photo_eeg_run_space_2 = tk.PhotoImage(file=all_path+\"icon/eeg_run_space.png\")\n",
    "#photo_eeg_run_space_2 = photo_eeg_run_space_2.zoom(4)\n",
    "#photo_eeg_run_space_2 = photo_eeg_run_space_2.subsample(8)\n",
    "\n",
    "\n",
    "photo_logo_1 = tk.PhotoImage(file=all_path+\"icon/北榮.png\") # 3 : 10\n",
    "photo_logo_1 = photo_logo_1.zoom(3)\n",
    "photo_logo_1 = photo_logo_1.subsample(10)\n",
    "\n",
    "photo_logo_2 = tk.PhotoImage(file=all_path+\"icon/中央.png\") # 4 : 10\n",
    "photo_logo_2 = photo_logo_2.zoom(4)\n",
    "photo_logo_2 = photo_logo_2.subsample(10)\n",
    "\n",
    "'''\n",
    "photo_logo_3 = tk.PhotoImage(file=all_path+\"icon/NLP.png\") # 1 : 14\n",
    "photo_logo_3 = photo_logo_3.zoom(1)\n",
    "photo_logo_3 = photo_logo_3.subsample(14)\n",
    "'''\n",
    "\n",
    "open_logo = False\n",
    "\n",
    "def step4(text_data,stroke_epilepsy_filter_erders):\n",
    "    if not os.path.isdir(path_wavelet+text_data[:-4]):\n",
    "        os.mkdir(path_wavelet+text_data[:-4])\n",
    "        \n",
    "        ans_stroke_epilepsy = np.zeros((len(stroke_epilepsy_filter_erders),21,23,12))\n",
    "\n",
    "        for data_len in range(len(stroke_epilepsy_filter_erders)):\n",
    "            \n",
    "            print(data_len+1,len(stroke_epilepsy_filter_erders))\n",
    "            for channel in range(21):\n",
    "                data=stroke_epilepsy_filter_erders[data_len][channel]\n",
    "                samplerate=250\n",
    "                N=2000\n",
    "\n",
    "                f1 = 8 \n",
    "                f2 = 30 \n",
    "                fstep=1\n",
    "\n",
    "                ts=[]\n",
    "                taxis = []\n",
    "                for i in range(1,int(N/4)+1):\n",
    "                    ts.append(i/samplerate)\n",
    "                for i in range(1,int(N)+1):\n",
    "                    taxis.append(i/samplerate)\n",
    "\n",
    "                spec = tfa_morlet(data, samplerate, f1, f2, fstep)\n",
    "                Mag=abs(np.array(spec))\n",
    "                for hz in range(23):\n",
    "                    for sec in range(4):\n",
    "                        e_value = entropy(spec[hz][0+500*sec:500+500*sec])\n",
    "                        s_value = skew(spec[hz][0+500*sec:500+500*sec])\n",
    "                        k_value = kurtosis(spec[hz][0+500*sec:500+500*sec])        \n",
    "                        ans_stroke_epilepsy[data_len][channel][hz][sec] = e_value\n",
    "                        ans_stroke_epilepsy[data_len][channel][hz][sec+4] = s_value\n",
    "                        ans_stroke_epilepsy[data_len][channel][hz][sec+8] = k_value    \n",
    "\n",
    "        np.save(path_wavelet+text_data[:-4]+'/stroke_epilepsy_filter_erders_wavelet_static' , np.array(ans_stroke_epilepsy))\n",
    "        \n",
    "def step3(text_data):\n",
    "    if not os.path.isdir(path_erd_ers+text_data[:-4]):\n",
    "        os.mkdir(path_erd_ers+text_data[:-4])\n",
    "\n",
    "        stroke_epilepsy_filter = np.load(path_bandpass+text_data[:-4]+'/stroke_epilepsy_filter.npy')\n",
    "        stroke_epilepsy_filter_erders = []\n",
    "        for data_8s in range(len(stroke_epilepsy_filter)):\n",
    "            print('stroke_epilepsy erd_ers......',data_8s+1,'/',len(stroke_epilepsy_filter))\n",
    "            stroke_epilepsy_filter_erders.append([])\n",
    "            for data_8s_channel in range(21):\n",
    "                data_8s_channel_mean = np.mean(stroke_epilepsy_filter[data_8s][data_8s_channel])\n",
    "                want_8s_erders = (stroke_epilepsy_filter[data_8s][data_8s_channel] - data_8s_channel_mean) / np.abs(data_8s_channel_mean)\n",
    "                stroke_epilepsy_filter_erders[data_8s].append(want_8s_erders.tolist())\n",
    "\n",
    "        np.save( path_erd_ers+text_data[:-4]+'/stroke_epilepsy_filter_erders' , np.array(stroke_epilepsy_filter_erders))\n",
    "        \n",
    "    else:\n",
    "        stroke_epilepsy_filter = np.load(path_bandpass+text_data[:-4]+'/stroke_epilepsy_filter.npy')\n",
    "        stroke_epilepsy_filter_erders = np.load( path_erd_ers+text_data[:-4]+'/stroke_epilepsy_filter_erders.npy')\n",
    "                                                \n",
    "    return stroke_epilepsy_filter_erders , len(stroke_epilepsy_filter)\n",
    "\n",
    "def step2(text_data):\n",
    "    if not os.path.isdir(path_bandpass+text_data[:-4]):\n",
    "        os.mkdir(path_bandpass+text_data[:-4])\n",
    "        \n",
    "        stroke_epilepsy = np.load(path_create+text_data[:-4]+'/after.npy')\n",
    "        stroke_epilepsy_id = np.load(path_create+text_data[:-4]+'/success_id.npy')\n",
    "\n",
    "        sampling_freq = 250 \n",
    "        duration = 8\n",
    "        t = np.arange(0.0, duration, 1/sampling_freq) \n",
    "        lowcut = 1\n",
    "        highcut = 50\n",
    "        fs = 250\n",
    "\n",
    "        filter = signal.firwin(numtaps=400, cutoff=[lowcut/(fs/2), highcut/(fs/2)], pass_zero=False) \n",
    "        stroke_epilepsy_filter = np.zeros([stroke_epilepsy.shape[0],stroke_epilepsy.shape[1]-1,stroke_epilepsy.shape[2]])\n",
    "\n",
    "        for run_epilepsy in range(stroke_epilepsy.shape[0]): #len(stroke_epilepsy.shape[0])\n",
    "            for run_21_channel in range(0,21):\n",
    "                y = stroke_epilepsy[run_epilepsy][run_21_channel]\n",
    "                y2 = signal.convolve(y, filter, mode='same')\n",
    "                stroke_epilepsy_filter[run_epilepsy][run_21_channel]=y2\n",
    "\n",
    "        data=np.delete(stroke_epilepsy_filter,0,axis=0)\n",
    "\n",
    "        np.save( path_bandpass+text_data[:-4]+'/stroke_epilepsy_filter' , np.array(data))\n",
    "\n",
    "def step1(text_data):\n",
    "\n",
    "    if not os.path.isdir(path_create+text_data[:-4]):\n",
    "        os.mkdir(path_create+text_data[:-4])\n",
    "        data = text_data\n",
    "\n",
    "        count_success_math=0\n",
    "        photo_times_list=[]\n",
    "        photo_size_diff_list = []\n",
    "        data_math=0\n",
    "        success_data=[]\n",
    "        fail_data=[]\n",
    "        fail_tidy_data=[]\n",
    "        success_id=[]\n",
    "        success_id_time=[]\n",
    "        success_eeg=[]\n",
    "        success_eeg_time=[]\n",
    "        want_sampling_rate=250\n",
    "        collect_data=np.zeros((1,22,2000))\n",
    "        collect_data_after=np.zeros((1,22,2000))\n",
    "        collect_data_befor=np.zeros((1,22,2000))\n",
    "\n",
    "        try:\n",
    "            raw = read_raw_edf(path_data+data, preload=True)\n",
    "            all_data = raw.get_data()\n",
    "            frequency=raw.info['sfreq']\n",
    "            channel_position=raw.info[\"ch_names\"]\n",
    "            select_data_save,sort_channel_list,success_or_not = tidy_up(channel_position,all_data)\n",
    "            if(success_or_not==1):\n",
    "\n",
    "                success_time,photo_times_list,photo_size_diff_list,data_math,collect_data,collect_data_after,collect_data_befor=photo_stimulate_position(photo_times_list,photo_size_diff_list,data_math,collect_data,collect_data_after,collect_data_befor,data[:-4],raw.info['sfreq'],want_sampling_rate,select_data_save)\n",
    "                success_data.append(data)\n",
    "                if(success_time!=0):\n",
    "                    success_eeg.append(data[:-6])\n",
    "                    success_eeg_time.append(success_time)\n",
    "                    if(data[:-6] not in success_id):\n",
    "                        success_id.append(data[:-6])\n",
    "                        success_id_time.append(success_time)\n",
    "                    else:\n",
    "                        success_id_time[-1]=int(success_id_time[-1])+success_time\n",
    "            else:\n",
    "                fail_tidy_data.append(data)\n",
    "            print(\"read success\")\n",
    "            count_success_math+=success_or_not\n",
    "        except:\n",
    "            print(\"read not success\")\n",
    "            fail_data.append(data)\n",
    "\n",
    "        print(\"tidy all\",len(success_data),\"success\",count_success_math)\n",
    "\n",
    "        np.save( path_create+text_data[:-4]+'/'+'now' , np.array(collect_data))\n",
    "        np.save( path_create+text_data[:-4]+'/'+'after' , np.array(collect_data_after))\n",
    "        np.save( path_create+text_data[:-4]+'/'+'befor' , np.array(collect_data_befor))\n",
    "        np.save( path_create+text_data[:-4]+'/'+'success_id' , np.array(success_id))\n",
    "        np.save( path_create+text_data[:-4]+'/'+'success_id_time' , np.array(success_id_time))\n",
    "        np.save( path_create+text_data[:-4]+'/'+'success_eeg' , np.array(success_eeg))\n",
    "        np.save( path_create+text_data[:-4]+'/'+'success_eeg_time' , np.array(success_eeg_time))\n",
    "        with open(path_create+text_data[:-4]+'/'+'success_id.txt','w',) as file_success :\n",
    "            for line in range(len(success_id)):\n",
    "                file_success.write(success_id[line]+' '+str(success_id_time[line])+'\\n')\n",
    "        with open(path_create+text_data[:-4]+'/'+'success_eeg.txt','w',) as file_success :\n",
    "            for line in range(len(success_eeg)):\n",
    "                file_success.write(success_eeg[line]+' '+str(success_eeg_time[line])+'\\n')\n",
    "    \n",
    "def show_ans_pic(text_data,text_model,data_8s_times,channel_num,ans_text_show,ans_text_show_2,color,eeg_ans,Notice_sec):\n",
    "    def check_21channel():\n",
    "        newWindow = tk.Toplevel(window)\n",
    "        newWindow.geometry('600x750') #470x300\n",
    "        newWindow.iconbitmap(all_path+'icon/eeg_icon.ico')\n",
    "        #newWindow.resizable(False, False)\n",
    "        newWindow.title(' Taipei Veterans General Hospital - Notice')\n",
    "        newWindow.configure(bg='white')\n",
    "        num = data_8s_times\n",
    "\n",
    "        stroke_epilepsy_filter = np.load(path_create+text_data[:-4]+'/befor.npy')\n",
    "\n",
    "        sampling_freq = 250 # 採樣頻率\n",
    "        duration = 8 # 持續秒數\n",
    "        t = np.arange(0.0, duration, 1/sampling_freq) #從0秒開始 週期\n",
    "        if(len(num2)<=2):\n",
    "            fig = Figure(figsize=(10,20), dpi=60)\n",
    "        elif(len(num2)<=4):\n",
    "            fig = Figure(figsize=(10,40), dpi=60)\n",
    "        elif(len(num2)<=6):\n",
    "            fig = Figure(figsize=(10,60), dpi=60)\n",
    "        elif(len(num2)<=8):\n",
    "            fig = Figure(figsize=(10,80), dpi=60)\n",
    "        elif(len(num2)<=10):\n",
    "            fig = Figure(figsize=(10,100), dpi=60)\n",
    "        \n",
    "        num_sec = 0\n",
    "        for i in num2:\n",
    "            for channel_num in range(21):\n",
    "                y = stroke_epilepsy_filter[i+1][channel_num]\n",
    "                fig.add_subplot(len(num2)*21,1,num_sec+1).plot(t,y)\n",
    "                num_sec+=1\n",
    "\n",
    "\n",
    "\n",
    "        canvas = FigureCanvasTkAgg(fig, master=newWindow)  # A tk.DrawingArea. root\n",
    "        canvas.draw()\n",
    "        #canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "\n",
    "        toolbar = NavigationToolbar2Tk(canvas, newWindow)\n",
    "        toolbar.update()\n",
    "        #canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "        \n",
    "        if(len(num2)<=2):\n",
    "            canvas.get_tk_widget().place(x=10, y=-70)\n",
    "        elif(len(num2)<=4):\n",
    "            canvas.get_tk_widget().place(x=10, y=-210)\n",
    "        elif(len(num2)<=6):\n",
    "            canvas.get_tk_widget().place(x=10, y=-350)\n",
    "        elif(len(num2)<=8):\n",
    "            canvas.get_tk_widget().place(x=10, y=-490)\n",
    "        elif(len(num2)<=10):\n",
    "            canvas.get_tk_widget().place(x=10, y=-630)\n",
    "        toolbar.place(x=173, y=10)\n",
    "        def on_key_press(event):\n",
    "            print(\"you pressed {}\".format(event.key))\n",
    "            key_press_handler(event, canvas, toolbar)\n",
    "\n",
    "\n",
    "        canvas.mpl_connect(\"key_press_event\", on_key_press)\n",
    "        print('has')\n",
    "    #eeg(text_data,data_8s_times)\n",
    "    \n",
    "    num2 = Notice_sec\n",
    "    \n",
    "    if(eeg_ans==1):\n",
    "        button_check_21_channel = tk.Button(window, text = \"統整\", command = check_21channel,font = 30)\n",
    "        button_check_21_channel.place(x=320, y=282)\n",
    "\n",
    "    num = data_8s_times\n",
    "    \n",
    "    stroke_epilepsy_filter = np.load(path_create+text_data[:-4]+'/befor.npy')\n",
    "\n",
    "    sampling_freq = 250 # 採樣頻率\n",
    "    duration = 8 # 持續秒數\n",
    "    t = np.arange(0.0, duration, 1/sampling_freq) #從0秒開始 週期\n",
    "    fig = Figure(figsize=(12, 10), dpi=60)\n",
    "    \n",
    "    for i in range(num):\n",
    "        y = stroke_epilepsy_filter[i+1][channel_num]\n",
    "        fig.add_subplot(num,1,i+1).plot(t,y)\n",
    "    \n",
    "\n",
    "\n",
    "    canvas = FigureCanvasTkAgg(fig, master=window)  # A tk.DrawingArea. root\n",
    "    canvas.draw()\n",
    "    #canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "\n",
    "    toolbar = NavigationToolbar2Tk(canvas, window)\n",
    "    toolbar.update()\n",
    "    #canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "    canvas.get_tk_widget().place(x=380, y=-55)\n",
    "    toolbar.place(x=622, y=575)\n",
    "    def on_key_press(event):\n",
    "        print(\"you pressed {}\".format(event.key))\n",
    "        key_press_handler(event, canvas, toolbar)\n",
    "\n",
    "\n",
    "    canvas.mpl_connect(\"key_press_event\", on_key_press)\n",
    "\n",
    "    label_data = tk.Label(window,text = text_data,bg='white',font = 30)\n",
    "    label_data.place(x=158, y=55)\n",
    "    label_model = tk.Label(window,text = text_model,bg='white',font = 30)\n",
    "    label_model.place(x=160, y=180)\n",
    "    label_data_show = tk.Label(window,text = ans_text_show ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    label_data_show.place(x=20, y=260,width=300, height=400)  \n",
    "    label_data_show_2 = tk.Label(window,text = ans_text_show_2 ,bg='white',fg=color,font =(\"Helvetica\",16))#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    label_data_show_2.place(x=265, y=282)\n",
    "    def _quit():\n",
    "        canvas.get_tk_widget().destroy()\n",
    "        toolbar.destroy()\n",
    "        label_data.destroy()\n",
    "        label_model.destroy()\n",
    "        label_data_show.destroy()\n",
    "        label_data_show_2.destroy()\n",
    "        button_return.destroy()\n",
    "        combo_channel.destroy()\n",
    "        try :\n",
    "            button_check_21_channel.destroy()\n",
    "        except:\n",
    "            True        \n",
    "        \n",
    "        data_model_choose()\n",
    "        \n",
    "    def other_channel(channel_position):\n",
    "\n",
    "        fig.clf()\n",
    "        for i in range(num):\n",
    "            y = stroke_epilepsy_filter[i+1][channel_position]\n",
    "            fig.add_subplot(num,1,i+1).plot(t,y)\n",
    "        canvas = FigureCanvasTkAgg(fig, master=window)  # A tk.DrawingArea. root\n",
    "        canvas.draw()\n",
    "        #canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "\n",
    "        #canvas.get_tk_widget().pack(side=tkinter.TOP, fill=tkinter.BOTH, expand=1)\n",
    "        canvas.get_tk_widget().place(x=380, y=-55)\n",
    "\n",
    "        def _quit():\n",
    "            canvas.get_tk_widget().destroy()\n",
    "            toolbar.destroy()\n",
    "            label_data.destroy()\n",
    "            label_model.destroy()\n",
    "            label_data_show.destroy()\n",
    "            label_data_show_2.destroy()\n",
    "            button_return.destroy()\n",
    "            combo_channel.destroy()\n",
    "            try :\n",
    "                button_check_21_channel.destroy()\n",
    "            except:\n",
    "                True\n",
    "            data_model_choose()\n",
    "\n",
    "        button_return = tkinter.Button(master=window, text=\"Return\", command=_quit,font = 30)\n",
    "        button_return.place(x=1040, y=575)#pack(side=tkinter.BOTTOM)          \n",
    "    \n",
    "    button_return = tkinter.Button(master=window, text=\"Return\", command=_quit,font = 30)\n",
    "    button_return.place(x=1040, y=575)#pack(side=tkinter.BOTTOM)    \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def callbackFunc_channel(event):\n",
    "        print(\"New channel Selected\",combo_channel.get())   \n",
    "        channel_position = channel_name.index(combo_channel.get())\n",
    "        canvas.get_tk_widget().destroy()\n",
    "        toolbar.destroy()\n",
    "        label_data.destroy()\n",
    "        label_model.destroy()\n",
    "        label_data_show.destroy()\n",
    "        label_data_show_2.destroy()\n",
    "        button_return.destroy()\n",
    "        combo_channel.destroy()\n",
    "        try :\n",
    "            button_check_21_channel.destroy()\n",
    "        except:\n",
    "            True\n",
    "        show_ans_pic(text_data,text_model,data_8s_times,channel_position,ans_text_show,ans_text_show_2,color,eeg_ans,Notice_sec)\n",
    "        \n",
    "    combo_channel = ttk.Combobox(window,values=channel_name ,width=12, height=8,font = 30)#,state=\"disabled\"\n",
    "    combo_channel.place(x=465, y=580)\n",
    "    combo_channel.current(0)\n",
    "    combo_channel.bind(\"<<ComboboxSelected>>\", callbackFunc_channel)\n",
    "\n",
    "def data_model_choose(): \n",
    "    def callbackFunc_data(event):\n",
    "        print(\"New Data Selected\",combo_data.get())\n",
    "        try:\n",
    "            print(path_data+combo_data.get())\n",
    "            raw = read_raw_edf(path_data+combo_data.get(), preload=True)\n",
    "            frequency=raw.info['sfreq']\n",
    "            \n",
    "            \n",
    "            timeStamp = str(raw.info['meas_date'])[:-6]+ ' GMT'\n",
    "#             timeArray = time.gmtime(timeStamp)\n",
    "#             otherStyleTime = time.strftime(\"%Y - %m - %d  %H : %M : %S GMT\", timeArray)\n",
    "            \n",
    "            lowpass_data = raw.info['lowpass']\n",
    "            '''\n",
    "            print(int((raw.n_times/frequency)/60),' min ',int((raw.n_times/frequency)%60),' sec')\n",
    "            print(frequency)\n",
    "            print(otherStyleTime)\n",
    "            print(lowpass)\n",
    "            print(raw.info)\n",
    "            print(raw)\n",
    "            \n",
    "            '''\n",
    "            string_data_1 = \"experiment date  :  \" + timeStamp \n",
    "            #string_data_1 = \"date        :  \" + otherStyleTime \n",
    "            string_data_2 = \"lowpass filter      :  \"+ str(int(lowpass_data)) +\" Hz.\"\n",
    "            string_data_3 = \"sampling frequency  :  \" + str(int(frequency)) +\" Hz.\"\n",
    "            string_data_4 = \"times duration           :  \" + str(int((raw.n_times/frequency)/60)) + \" Min. \" + str(int((raw.n_times/frequency)%60)) + \" Sec.\"\n",
    "\n",
    "            data_intro_1.set(string_data_1)\n",
    "            data_intro_2.set(string_data_2)\n",
    "            data_intro_3.set(string_data_3)\n",
    "            data_intro_4.set(string_data_4)\n",
    "            \n",
    "        except:\n",
    "            #print(\"reading False\")\n",
    "            string_data_1 = \"experiment date  :  \" + \"reading False\"\n",
    "            string_data_2 = \"lowpass filter      :  \"+ \"reading False\"\n",
    "            string_data_3 = \"sampling frequency  :  \" + \"reading False\"\n",
    "            string_data_4 = \"times duration           :  \" + \"reading False\"\n",
    "            data_intro_1.set(string_data_1)\n",
    "            data_intro_2.set(string_data_2)\n",
    "            data_intro_3.set(string_data_3)\n",
    "            data_intro_4.set(string_data_4)\n",
    "        \n",
    "        \n",
    "    def callbackFunc_model(event):\n",
    "        print(\"New Model Selected\",combo_model.get())\n",
    "        sentence_list = []\n",
    "        with open(path_model_intro+combo_model.get()[:-7]+\".txt\",'r',encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                sentence_list.append(line)\n",
    "        model_intro_1.set(sentence_list[0][:-1])\n",
    "        model_intro_2.set(sentence_list[1][:-1])\n",
    "        model_intro_3.set(sentence_list[2][:-1])\n",
    "        model_intro_4.set(sentence_list[3][:-1])\n",
    "        model_intro_5.set(sentence_list[4][:-1])\n",
    "\n",
    "    #imgLabel_eeg_run_space_1 = tk.Label(window,image=photo_eeg_run_space_1,bg='white')\n",
    "    #imgLabel_eeg_run_space_1.place(x=30, y=450+add_pic)  \n",
    "    #imgLabel_eeg_run_space_2 = tk.Label(window,image=photo_eeg_run_space_2,bg='white')\n",
    "    #imgLabel_eeg_run_space_2.place(x=370, y=450+add_pic)\n",
    "\n",
    "    \n",
    "    data_intro_1 = tk.StringVar()\n",
    "    data_intro_1.set('')\n",
    "    data_intro_2 = tk.StringVar()\n",
    "    data_intro_2.set('')\n",
    "    data_intro_3 = tk.StringVar()\n",
    "    data_intro_3.set('')\n",
    "    data_intro_4 = tk.StringVar()\n",
    "    data_intro_4.set('')\n",
    "    \n",
    "\n",
    "    model_intro_1 = tk.StringVar()\n",
    "    model_intro_1.set('')\n",
    "    model_intro_2 = tk.StringVar()\n",
    "    model_intro_2.set('')\n",
    "    model_intro_3 = tk.StringVar()\n",
    "    model_intro_3.set('')\n",
    "    model_intro_4 = tk.StringVar()\n",
    "    model_intro_4.set('')\n",
    "    model_intro_5 = tk.StringVar()\n",
    "    model_intro_5.set('')\n",
    "    \n",
    "    #data_intro = \"\"\n",
    "    label_data_intro_1 = tk.Label(window,textvariable = data_intro_1 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    label_data_intro_1.place(x=420, y=30+add_pic)    \n",
    "    label_data_intro_2 = tk.Label(window,textvariable = data_intro_2 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    label_data_intro_2.place(x=420, y=70+add_pic) \n",
    "    label_data_intro_3 = tk.Label(window,textvariable = data_intro_3 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    label_data_intro_3.place(x=790, y=30+add_pic) \n",
    "    label_data_intro_4 = tk.Label(window,textvariable = data_intro_4 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    label_data_intro_4.place(x=790, y=70+add_pic) \n",
    "    \n",
    "    model_data_intro_1 = tk.Label(window,textvariable = model_intro_1 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    model_data_intro_1.place(x=420, y=150+add_pic)    \n",
    "    model_data_intro_2 = tk.Label(window,textvariable = model_intro_2 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    model_data_intro_2.place(x=420, y=190+add_pic) \n",
    "    model_data_intro_3 = tk.Label(window,textvariable = model_intro_3 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    model_data_intro_3.place(x=790, y=150+add_pic) \n",
    "    model_data_intro_4 = tk.Label(window,textvariable = model_intro_4 ,bg='white',font = tkFont.Font(family=\"Lucida Grande\", size=9))#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    model_data_intro_4.place(x=974, y=154+add_pic) \n",
    "    model_data_intro_5 = tk.Label(window,textvariable = model_intro_5 ,bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    model_data_intro_5.place(x=790, y=190+add_pic) \n",
    "\n",
    "    if(open_logo == True):\n",
    "    \n",
    "        imgLabel_logo_1 = tk.Label(window,image=photo_logo_1,bg='white')#把圖片整合到標簽類中 # 30 300 150\n",
    "        imgLabel_logo_1.place(x=420+600, y=560+add_pic)    \n",
    "\n",
    "        copyright = \"Ver. : 0.1.0 Updated : March 4, 2020 || © 2020- Copyright : NCU || Co-development : National Central University                      Taipei Veterans General Hospital\"\n",
    "        label_copyright = tk.Label(window,text = copyright,bg='white',font = 30)\n",
    "        label_copyright.place(x=5, y=620)\n",
    "\n",
    "        imgLabel_logo_2 = tk.Label(window,image=photo_logo_2,bg='white')#把圖片整合到標簽類中\n",
    "        imgLabel_logo_2.place(x=120+600, y=560+add_pic)      \n",
    "    else:\n",
    "        \n",
    "        copyright = \"Ver. : 0.1.0     ||     Updated : March 4, 2020     ||     © 2020- Copyright : NCU     ||     Co-development : National Central University   &   Taipei Veterans General Hospital\"\n",
    "        label_copyright = tk.Label(window,text = copyright,bg='white',font = 30)\n",
    "        label_copyright.place(x=15, y=620)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    '''\n",
    "    imgLabel_logo_3 = tk.Label(window,image=photo_logo_3,bg='black')#把圖片整合到標簽類中\n",
    "    imgLabel_logo_3.place(x=300+600, y=567+add_pic)\n",
    "    '''\n",
    "\n",
    "    \n",
    "    label_data = tk.Label(window,text = \"Choose your data\",bg='white',font = 30)#,font = 30  tkFont.Font(family=\"Lucida Grande\", size=20)\n",
    "    label_data.place(x=160, y=30+add_pic)\n",
    "    combo_data = ttk.Combobox(window,values=data_name ,width=19, height=3,font = 30)\n",
    "    combo_data.place(x=160, y=65+add_pic)\n",
    "    combo_data.current(0)\n",
    "    combo_data.bind(\"<<ComboboxSelected>>\", callbackFunc_data)\n",
    "\n",
    "    label_model = tk.Label(window,text = \"Choose your model\",bg='white',font = 30)\n",
    "    label_model.place(x=160, y=150+add_pic)\n",
    "    combo_model = ttk.Combobox(window,values=model_name,width=19, height=3,font = 30)\n",
    "    combo_model.place(x=160, y=185+add_pic)\n",
    "    combo_model.current(0)\n",
    "    combo_model.bind(\"<<ComboboxSelected>>\", callbackFunc_model)\n",
    "\n",
    "    canvas_size = 180\n",
    "    canvas_1 = tk.Canvas(window, width=canvas_size, height=22, bg=\"white\")\n",
    "    canvas_1.place(x=20, y=300+add_num)\n",
    "    canvas_2 = tk.Canvas(window, width=canvas_size, height=22, bg=\"white\")\n",
    "    canvas_2.place(x=20+canvas_size*1, y=300+add_num)\n",
    "    canvas_3 = tk.Canvas(window, width=canvas_size, height=22, bg=\"white\")\n",
    "    canvas_3.place(x=20+canvas_size*2, y=300+add_num)\n",
    "    canvas_4 = tk.Canvas(window, width=canvas_size, height=22, bg=\"white\")\n",
    "    canvas_4.place(x=20+canvas_size*3, y=300+add_num)\n",
    "\n",
    "    fill_line_1 = canvas_1.create_rectangle(1.5, 1.5, 0, 23, width=0, fill=\"green\")\n",
    "    fill_line_2 = canvas_2.create_rectangle(1.5, 1.5, 0, 23, width=0, fill=\"green\")\n",
    "    fill_line_3 = canvas_3.create_rectangle(1.5, 1.5, 0, 23, width=0, fill=\"green\")\n",
    "    fill_line_4 = canvas_4.create_rectangle(1.5, 1.5, 0, 23, width=0, fill=\"green\")\n",
    "\n",
    "    label_run_step1 = tk.Label(window, text='preprocessing', bg=\"white\" ,font = 30) #width=15, height=2\n",
    "    label_run_step1.place(x=61, y=302+add_num)\n",
    "    label_run_step2 = tk.Label(window, text='bandpass filtering', bg=\"white\" ,font = 30)\n",
    "    label_run_step2.place(x=230, y=302+add_num)\n",
    "    label_run_step3 = tk.Label(window, text='CSP Filtering', bg=\"white\" ,font = 30)\n",
    "    label_run_step3.place(x=425, y=302+add_num)\n",
    "    label_run_step4 = tk.Label(window, text='wavelet transform', bg=\"white\" ,font = 30)\n",
    "    label_run_step4.place(x=590, y=302+add_num)\n",
    "\n",
    "    steps_position = 75\n",
    "    label_step1 = tk.Label(window, text='steps 1', bg=\"white\" , font=(\"Helvetica\",15))\n",
    "    label_step1.place(x=steps_position, y=265+add_num)\n",
    "    label_step2 = tk.Label(window, text='steps 2', bg=\"white\" , font=(\"Helvetica\",15))\n",
    "    label_step2.place(x=steps_position+canvas_size*1, y=265+add_num)\n",
    "    label_step3 = tk.Label(window, text='steps 3', bg=\"white\" , font=(\"Helvetica\",15))\n",
    "    label_step3.place(x=steps_position+canvas_size*2, y=265+add_num)\n",
    "    label_step4 = tk.Label(window, text='steps 4', bg=\"white\" , font=(\"Helvetica\",15))\n",
    "    label_step4.place(x=steps_position+canvas_size*3, y=265+add_num)\n",
    "\n",
    "    path_step = all_path+'step/'\n",
    "    path_def = all_path+'data'\n",
    "\n",
    "        \n",
    "    def progress():\n",
    "        print(window.winfo_screenwidth(),window.winfo_screenheight() ) #window.winfo_reqwidth(),window.winfo_reqheight() \n",
    "        \n",
    "        n = 0\n",
    "        text_data = combo_data.get()\n",
    "        text_model = combo_model.get()\n",
    "        print(text_data)\n",
    "        print(text_model)\n",
    "\n",
    "        with open(path_model+text_model, 'rb') as f:\n",
    "            clf = pickle.load(f)\n",
    "\n",
    "\n",
    "            \n",
    "        step1(text_data)\n",
    "        imgLabel_eeg_run_1 = tk.Label(window,image=photo_eeg_run_1,bg='white',width=150)\n",
    "        \n",
    "        n = n + canvas_size / 1\n",
    "        canvas_1.coords(fill_line_1, (0, 0, n, 60))\n",
    "        label_run_step1_2 = tk.Label(window, text='preprocessing', fg=\"white\",bg=\"green\" ,font = 30)\n",
    "        label_run_step1_2.place(x=61, y=302+add_num)\n",
    "        window.update()\n",
    "\n",
    "        step2(text_data)\n",
    "        imgLabel_eeg_run_1.destroy()\n",
    "        imgLabel_eeg_run_1 = tk.Label(window,image=photo_eeg_run_1,bg='white',width=340)\n",
    "        imgLabel_eeg_run_1.place(x=30, y=450+add_pic)\n",
    "        \n",
    "        n = n + canvas_size / 1\n",
    "        canvas_2.coords(fill_line_2, (0, 0, n, 60))\n",
    "        label_run_step2_2 = tk.Label(window, text='bandpass filtering', bg=\"green\" , fg=\"white\",font = 30)\n",
    "        label_run_step2_2.place(x=230, y=302+add_num)\n",
    "        window.update()\n",
    "        \n",
    "        step3_data , data_8s_times = step3(text_data)\n",
    "        imgLabel_eeg_run_2 = tk.Label(window,image=photo_eeg_run_2,bg='white',width=170)\n",
    "        imgLabel_eeg_run_2.place(x=370, y=450+add_pic)\n",
    "        n = n + canvas_size / 1\n",
    "        canvas_3.coords(fill_line_3, (0, 0, n, 60))\n",
    "        label_run_step3_2 = tk.Label(window, text='CSP Filtering', bg=\"green\" , fg=\"white\",font = 30)\n",
    "        label_run_step3_2.place(x=425, y=302+add_num)\n",
    "        window.update()\n",
    "\n",
    "        step4(text_data,step3_data)\n",
    "        imgLabel_eeg_run_2.destroy()\n",
    "        imgLabel_eeg_run_2 = tk.Label(window,image=photo_eeg_run_2,bg='white',width=360)\n",
    "        imgLabel_eeg_run_2.place(x=370, y=450+add_pic)\n",
    "        n = n + canvas_size / 1\n",
    "        canvas_4.coords(fill_line_4, (0, 0, n, 60))\n",
    "        label_run_step4_2 = tk.Label(window, text='wavelet transform', bg=\"green\", fg=\"white\" ,font = 30)\n",
    "        label_run_step4_2.place(x=590, y=302+add_num)\n",
    "        window.update()\n",
    "\n",
    "        \n",
    "        label_data_intro_1.destroy()\n",
    "        label_data_intro_2.destroy()\n",
    "        label_data_intro_3.destroy()\n",
    "        label_data_intro_4.destroy()\n",
    "        \n",
    "        model_data_intro_1.destroy()\n",
    "        model_data_intro_2.destroy()\n",
    "        model_data_intro_3.destroy()\n",
    "        model_data_intro_4.destroy()\n",
    "        model_data_intro_5.destroy()\n",
    "\n",
    "        label_data.destroy()\n",
    "        combo_data.destroy()\n",
    "        label_model.destroy()\n",
    "        combo_model.destroy()\n",
    "        canvas_1.destroy()\n",
    "        canvas_2.destroy()\n",
    "        canvas_3.destroy()\n",
    "        canvas_4.destroy()\n",
    "        label_run_step1.destroy()\n",
    "        label_run_step2.destroy()\n",
    "        label_run_step3.destroy()\n",
    "        label_run_step4.destroy()\n",
    "        label_run_step1_2.destroy()\n",
    "        label_run_step2_2.destroy()\n",
    "        label_run_step3_2.destroy()\n",
    "        label_run_step4_2.destroy()\n",
    "        label_step1.destroy()\n",
    "        label_step2.destroy()\n",
    "        label_step3.destroy()\n",
    "        label_step4.destroy()\n",
    "        button.destroy()        \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "        with open (path_create+text_data[:-4]+'/'+'success_eeg.txt','r') as eeg_file :\n",
    "            stroke_epilepsy_eeg = []\n",
    "            #label_eeg = []\n",
    "            run_time = 0\n",
    "            start_position = 0\n",
    "            for line in eeg_file :\n",
    "                a,b = line.split()\n",
    "                stroke_epilepsy_eeg.append([])\n",
    "                stroke_epilepsy_eeg[run_time].append(run_time+1)\n",
    "                stroke_epilepsy_eeg[run_time].append(a)\n",
    "                stroke_epilepsy_eeg[run_time].append(start_position)\n",
    "                stroke_epilepsy_eeg[run_time].append(start_position+int(b))\n",
    "                stroke_epilepsy_eeg[run_time].append(1)\n",
    "                start_position+=int(b)\n",
    "                #label_eeg.append(1)\n",
    "                run_time+=1\n",
    "\n",
    "\n",
    "        with open (path_create+text_data[:-4]+'/'+'success_id.txt','r') as eeg_file :\n",
    "            stroke_epilepsy_id = []\n",
    "            #label_id = []\n",
    "            run_time = 0\n",
    "            start_position = 0\n",
    "            for line in eeg_file :\n",
    "                a,b = line.split()\n",
    "                stroke_epilepsy_id.append([])\n",
    "                stroke_epilepsy_id[run_time].append(run_time+1)\n",
    "                stroke_epilepsy_id[run_time].append(a)\n",
    "                stroke_epilepsy_id[run_time].append(start_position)\n",
    "                stroke_epilepsy_id[run_time].append(start_position+int(b))\n",
    "                stroke_epilepsy_id[run_time].append(1)\n",
    "                start_position+=int(b)\n",
    "                #label_id.append(1)\n",
    "                run_time+=1\n",
    "\n",
    "        num_tree = 100\n",
    "\n",
    "        stroke_epilepsy_8s = np.load(path_wavelet+text_data[:-4]+'/'+'stroke_epilepsy_filter_erders_wavelet_static.npy')\n",
    "        stroke_8s_old = stroke_epilepsy_8s\n",
    "\n",
    "        stroke_8s = np.zeros([stroke_8s_old.shape[0],21*23*12])\n",
    "        for data_combine_channel_hz in range(stroke_8s_old.shape[0]):\n",
    "            hz_channel = 0\n",
    "            for channel in range(21):\n",
    "                for hz in range(23):\n",
    "                    stroke_8s[data_combine_channel_hz][ 0+12*hz_channel : 12+12*hz_channel ] = stroke_8s_old[data_combine_channel_hz][channel][hz]\n",
    "                    hz_channel+=1\n",
    "\n",
    "        test_feature = []\n",
    "        #test_label = []\n",
    "        test_feature_judge_record = []\n",
    "\n",
    "        count_train_eeg = 0\n",
    "        count_train_8s = 0\n",
    "        for copy_feature in range(len(stroke_epilepsy_eeg)):\n",
    "            test_feature_judge_record.append([])\n",
    "            test_feature_judge_record[count_train_eeg].append(stroke_epilepsy_eeg[copy_feature][1])\n",
    "            test_feature_judge_record[count_train_eeg].append(count_train_8s)\n",
    "            for need_space in range(int(stroke_epilepsy_eeg[copy_feature][3])-int(stroke_epilepsy_eeg[copy_feature][2])):\n",
    "                test_feature.append([])\n",
    "                test_feature[count_train_8s] = stroke_8s[stroke_epilepsy_eeg[copy_feature][2]+need_space]\n",
    "                #test_label.append(stroke_epilepsy_eeg[copy_feature][4])\n",
    "                count_train_8s+=1\n",
    "            test_feature_judge_record[count_train_eeg].append(count_train_8s)\n",
    "            test_feature_judge_record[count_train_eeg].append(stroke_epilepsy_eeg[copy_feature][4])\n",
    "            count_train_eeg+=1\n",
    "\n",
    "        ans_inside = clf.predict(test_feature)\n",
    "        ans_clf = ans_inside\n",
    "        pro_clf = clf.predict_proba(test_feature)\n",
    "        #print(classification_report(test_label, ans_inside))\n",
    "        print(ans_inside)\n",
    "        threshold = 0.01\n",
    "        eeg_ans = []\n",
    "        now_8s_ans_position = 0\n",
    "        for test_eeg in range(len(test_feature_judge_record)):\n",
    "            this_ans = 0\n",
    "            this_eeg_times = int(test_feature_judge_record[test_eeg][2]) - int(test_feature_judge_record[test_eeg][1]) \n",
    "            for each_ans in range(this_eeg_times):\n",
    "                this_ans+=int(ans_inside[now_8s_ans_position])\n",
    "                now_8s_ans_position+=1\n",
    "            if(this_ans/this_eeg_times >= threshold * this_eeg_times):\n",
    "                eeg_ans.append(1)\n",
    "            else:\n",
    "                eeg_ans.append(0)\n",
    "        #print(classification_report(label_eeg, eeg_ans))\n",
    "        with open(path_ans+text_data[:-4]+'record_eeg_8s.txt','w') as file_8s:\n",
    "            for test_ans_8s in ans_inside :\n",
    "                file_8s.write(str(test_ans_8s))\n",
    "            #file_8s.write(classification_report(label_eeg, eeg_ans))\n",
    "        print(eeg_ans[0])\n",
    "        ans_text_show = '認為中風後癲癇可能 : '\n",
    "        ans_text_show_2 = ''\n",
    "        color = 'black'\n",
    "        if(eeg_ans[0]==1):\n",
    "            ans_text_show += '是\\n\\n'\n",
    "            ans_text_show_2 = '⚠'\n",
    "            color = 'red'\n",
    "\n",
    "        else:\n",
    "            ans_text_show += '否\\n\\n'\n",
    "            ans_text_show_2 = ''\n",
    "            color = 'black'\n",
    "            \n",
    "        Notice_sec = []    \n",
    "        for times in range(len(ans_inside)):\n",
    "            add_str = '第 '+str(times+1)+' 段 8 秒 '\n",
    "            if(ans_inside[times]==1):\n",
    "                add_str += ('▲ %.2f\\n\\n'%pro_clf[times][1])\n",
    "                Notice_sec.append(times)\n",
    "            else:\n",
    "                add_str += ('△ %.2f\\n\\n'%pro_clf[times][1])\n",
    "            \n",
    "            ans_text_show += add_str\n",
    "            \n",
    "            \n",
    "        if(open_logo == True):\n",
    "            imgLabel_logo_1.destroy()\n",
    "            imgLabel_logo_2.destroy()\n",
    "            label_copyright.destroy()\n",
    "        else :\n",
    "            label_copyright.destroy()\n",
    "\n",
    "        imgLabel_eeg_run_1.destroy()\n",
    "        imgLabel_eeg_run_2.destroy()\n",
    "        #imgLabel_logo_3.destroy()\n",
    "        show_ans_pic(text_data,text_model,data_8s_times,0,ans_text_show,ans_text_show_2,color,eeg_ans[0],Notice_sec)\n",
    "    \n",
    "    \n",
    "    #button =ttk.Button(window, text = \"點擊之後\\n執行預測\", command = progress,width=15 )\n",
    "    #button.place(x=800, y=293+add_num)\n",
    "    button = tk.Button(window, text = \"執行\", command = progress,font = 30)\n",
    "    button.place(x=800, y=298+add_num)\n",
    "\n",
    "data_model_choose()\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
